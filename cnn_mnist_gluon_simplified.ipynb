{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Interface for Gluon simplified in a similar manner to symbolic interface\n",
    "\n",
    "Transition from symbolic MXNet to Gluon simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "mx.random.seed(1)\n",
    "\n",
    "class BaseCNNClassifier(mx.gluon.Block):\n",
    "    def __init__(self, ctx):\n",
    "        super(BaseCNNClassifier, self).__init__()\n",
    "        self.ctx = ctx\n",
    "        self.net = None\n",
    "        \n",
    "    #@override\n",
    "    def build_model(self, convs, num_fc, num_classes):\n",
    "        '''\n",
    "        Default activation is relu\n",
    "        '''\n",
    "        # convs = [(channel, kernel_sz, pool_siz)triplets *N]\n",
    "        cnn_layers = gluon.nn.HybridSequential(prefix='')\n",
    "        for ch, k_sz, p_sz in convs:\n",
    "            cnn_layers.add(gluon.nn.Conv2D(channels=ch, kernel_size=k_sz, activation='relu'))\n",
    "            cnn_layers.add(gluon.nn.MaxPool2D(pool_size=p_sz, strides=2)) # strides fixed for now\n",
    "            \n",
    "        net = gluon.nn.HybridSequential()\n",
    "        with net.name_scope():\n",
    "            net.add(cnn_layers)\n",
    "            # Flatten and apply fully connected layers\n",
    "            net.add(gluon.nn.Flatten())\n",
    "            net.add(gluon.nn.Dense(num_fc, activation=\"relu\"))\n",
    "            net.add(gluon.nn.Dense(num_classes))\n",
    "\n",
    "        # speed up execution with hybridization\n",
    "        net.hybridize()\n",
    "        self.net = net\n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def compile_model(self, loss=None, optimizer='sgd', lr=1E-3, init_mg=2.24):\n",
    "        print self.net\n",
    "        self.net.collect_params().initialize(mx.init.Xavier(magnitude=init_mg), ctx=self.ctx)\n",
    "        self.loss = gluon.loss.SoftmaxCrossEntropyLoss() if loss is None else loss\n",
    "        self.optimizer = mx.gluon.Trainer(self.net.collect_params(), \n",
    "                                          optimizer, {'learning_rate': lr})\n",
    "    \n",
    "    def evaluate_accuracy(self, data_iterator):\n",
    "        acc = mx.metric.Accuracy()\n",
    "        for i, (data, label) in enumerate(data_iterator):\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            output = self.net(data)\n",
    "            predictions = nd.argmax(output, axis=1)\n",
    "            acc.update(preds=predictions, labels=label)\n",
    "        return acc.get()[1]\n",
    "    \n",
    "    def fit(self, train_data, test_data, epochs):\n",
    "        \n",
    "        smoothing_constant = .01\n",
    "        ctx = self.ctx\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for i, (data, label) in enumerate(train_data):\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                with autograd.record(train_mode=True):\n",
    "                    output = self.net(data)\n",
    "                    loss = self.loss(output, label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step(data.shape[0])\n",
    "\n",
    "                ##########################\n",
    "                #  Keep a moving average of the losses\n",
    "                ##########################\n",
    "                curr_loss = nd.mean(loss).asscalar()\n",
    "                moving_loss = (curr_loss if ((i == 0) and (e == 0)) \n",
    "                               else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "            test_accuracy = self.evaluate_accuracy(test_data)\n",
    "            train_accuracy = self.evaluate_accuracy(train_data)\n",
    "            print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "def transform(data, label):\n",
    "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_fc = 512\n",
    "num_classes = 10 #num_outputs\n",
    "convs = [(20,5,2), (50,5,2)]\n",
    "\n",
    "ctx = mx.gpu()\n",
    "cnn = BaseCNNClassifier(ctx)\n",
    "cnn.build_model(convs, num_fc, num_classes)\n",
    "cnn.compile_model(optimizer='adam')\n",
    "cnn.fit(train_data, test_data, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lets try CIFAR now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=transformer),\n",
    "    batch_size=batch_size, shuffle=True, last_batch='discard')\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=False, transform=transformer),\n",
    "    batch_size=batch_size, shuffle=False, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): HybridSequential(\n",
      "    (0): Conv2D(50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (2): Conv2D(50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (4): Conv2D(100, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (6): Conv2D(100, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (1): Flatten\n",
      "  (2): Dense(512, Activation(relu))\n",
      "  (3): Dense(10, linear)\n",
      ")\n",
      "Epoch 0. Loss: 1.47114814304, Train_acc 0.511003521127, Test_acc 0.474959935897\n",
      "Epoch 1. Loss: 1.23667258255, Train_acc 0.602792893726, Test_acc 0.546875\n",
      "Epoch 2. Loss: 1.04258822086, Train_acc 0.72685259283, Test_acc 0.608173076923\n",
      "Epoch 3. Loss: 0.844378689356, Train_acc 0.828885243278, Test_acc 0.62359775641\n",
      "Epoch 4. Loss: 0.628420212727, Train_acc 0.881722151088, Test_acc 0.612279647436\n"
     ]
    }
   ],
   "source": [
    "num_fc = 512\n",
    "num_classes = 10 #num_outputs\n",
    "convs = [(50,3,2), (50,3,2), (100,3,2), (100,3,2)]\n",
    "\n",
    "ctx = mx.gpu()\n",
    "cnn = BaseCNNClassifier(ctx)\n",
    "cnn.build_model(convs, num_fc, num_classes)\n",
    "cnn.compile_model(optimizer='adam')\n",
    "cnn.fit(train_data, test_data, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
