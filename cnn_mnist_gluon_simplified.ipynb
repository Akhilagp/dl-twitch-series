{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Interface for Gluon simplified in a similar manner to symbolic interface\n",
    "\n",
    "Transition from symbolic MXNet to Gluon simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "mx.random.seed(1)\n",
    "\n",
    "class BaseCNNClassifier(mx.gluon.Block):\n",
    "    def __init__(self, ctx):\n",
    "        super(BaseCNNClassifier, self).__init__()\n",
    "        self.ctx = ctx\n",
    "        self.net = None\n",
    "        \n",
    "    #@override\n",
    "    def build_model(self, convs, num_fc, num_classes):\n",
    "        '''\n",
    "        Default activation is relu\n",
    "        '''\n",
    "        # convs = [(channel, kernel_sz, pool_siz)triplets *N]\n",
    "        cnn_layers = gluon.nn.HybridSequential(prefix='')\n",
    "        for ch, k_sz, p_sz in convs:\n",
    "            cnn_layers.add(gluon.nn.Conv2D(channels=ch, kernel_size=k_sz, activation='relu'))\n",
    "            cnn_layers.add(gluon.nn.MaxPool2D(pool_size=p_sz, strides=2)) # strides fixed for now\n",
    "            \n",
    "        net = gluon.nn.HybridSequential()\n",
    "        with net.name_scope():\n",
    "            net.add(cnn_layers)\n",
    "            # Flatten and apply fully connected layers\n",
    "            net.add(gluon.nn.Flatten())\n",
    "            net.add(gluon.nn.Dense(num_fc, activation=\"relu\"))\n",
    "            net.add(gluon.nn.Dense(num_classes))\n",
    "\n",
    "        # speed up execution with hybridization\n",
    "        net.hybridize()\n",
    "        self.net = net\n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def compile_model(self, loss=None, optimizer='sgd', lr=1E-3, init_mg=2.24):\n",
    "        print self.net\n",
    "        self.net.collect_params().initialize(mx.init.Xavier(magnitude=init_mg), ctx=self.ctx)\n",
    "        self.loss = gluon.loss.SoftmaxCrossEntropyLoss() if loss is None else loss\n",
    "        self.optimizer = mx.gluon.Trainer(self.net.collect_params(), \n",
    "                                          optimizer, {'learning_rate': lr})\n",
    "    \n",
    "    def evaluate_accuracy(self, data_iterator):\n",
    "        acc = mx.metric.Accuracy()\n",
    "        for i, (data, label) in enumerate(data_iterator):\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            output = self.net(data)\n",
    "            predictions = nd.argmax(output, axis=1)\n",
    "            acc.update(preds=predictions, labels=label)\n",
    "        return acc.get()[1]\n",
    "    \n",
    "    def fit(self, train_data, test_data, epochs):\n",
    "        \n",
    "        smoothing_constant = .01\n",
    "        ctx = self.ctx\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            for i, (data, label) in enumerate(train_data):\n",
    "                data = data.as_in_context(ctx)\n",
    "                label = label.as_in_context(ctx)\n",
    "                with autograd.record(train_mode=True):\n",
    "                    output = self.net(data)\n",
    "                    loss = self.loss(output, label)\n",
    "                loss.backward()\n",
    "                self.optimizer.step(data.shape[0])\n",
    "\n",
    "                ##########################\n",
    "                #  Keep a moving average of the losses\n",
    "                ##########################\n",
    "                curr_loss = nd.mean(loss).asscalar()\n",
    "                moving_loss = (curr_loss if ((i == 0) and (e == 0)) \n",
    "                               else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "            test_accuracy = self.evaluate_accuracy(test_data)\n",
    "            train_accuracy = self.evaluate_accuracy(train_data)\n",
    "            print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "def transform(data, label):\n",
    "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_batch_sampler': <mxnet.gluon.data.sampler.BatchSampler at 0x10b07bd10>,\n",
       " '_dataset': <mxnet.gluon.data.vision.MNIST at 0x10b07ba50>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): HybridSequential(\n",
      "    (0): Conv2D(20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (2): Conv2D(50, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (1): Flatten\n",
      "  (2): Dense(512, Activation(relu))\n",
      "  (3): Dense(10, linear)\n",
      ")\n",
      "Epoch 0. Loss: 0.0550339012977, Train_acc 0.987516666667, Test_acc 0.9882\n",
      "Epoch 1. Loss: 0.0430203394256, Train_acc 0.991333333333, Test_acc 0.9901\n",
      "Epoch 2. Loss: 0.0261364316174, Train_acc 0.994883333333, Test_acc 0.991\n",
      "Epoch 3. Loss: 0.0220908905365, Train_acc 0.996566666667, Test_acc 0.9921\n",
      "Epoch 4. Loss: 0.0174940514529, Train_acc 0.996866666667, Test_acc 0.9919\n",
      "Epoch 5. Loss: 0.0138277958493, Train_acc 0.997283333333, Test_acc 0.9901\n",
      "Epoch 6. Loss: 0.0104377611519, Train_acc 0.998066666667, Test_acc 0.9921\n",
      "Epoch 7. Loss: 0.0120992395219, Train_acc 0.998816666667, Test_acc 0.9929\n",
      "Epoch 8. Loss: 0.00728318977314, Train_acc 0.996816666667, Test_acc 0.9894\n",
      "Epoch 9. Loss: 0.00985936332206, Train_acc 0.995416666667, Test_acc 0.9877\n"
     ]
    }
   ],
   "source": [
    "num_fc = 512\n",
    "num_classes = 10 #num_outputs\n",
    "convs = [(20,5,2), (50,5,2)]\n",
    "\n",
    "ctx = mx.cpu()\n",
    "cnn = BaseCNNClassifier(ctx)\n",
    "cnn.build_model(convs, num_fc, num_classes)\n",
    "cnn.compile_model(optimizer='adam')\n",
    "cnn.fit(train_data, test_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do CIFAR\n",
    "\n",
    "https://github.com/ilkarman/DeepLearningFrameworks/blob/master/Gluon_CIFAR.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try CIFAR now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Done.\n",
      "Extracting files...\n",
      "Done.\n",
      "Preparing train set...\n",
      "Preparing test set...\n",
      "Done.\n",
      "((50000, 3, 32, 32), (10000, 3, 32, 32), (50000,), (10000,))\n",
      "(dtype('float32'), dtype('float32'), dtype('int32'), dtype('int32'))\n",
      "CPU times: user 5.27 s, sys: 3.81 s, total: 9.08 s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import *\n",
    "\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(channel_first=True)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = self.from_numpy(X_train, y_train)\n",
    "train_loader = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(X_train, y_train),\n",
    "                                                batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ./data/cifar-10-binary.tar.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/cifar10/cifar-10-binary.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "def transformer(data, label):\n",
    "    data = mx.image.imresize(data, 224, 224)\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    data = data.astype(np.float32)\n",
    "    return data, label\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=True, transform=transformer),\n",
    "    batch_size=batch_size, shuffle=True, last_batch='discard')\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR10('./data', train=False, transform=transformer),\n",
    "    batch_size=batch_size, shuffle=False, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridSequential(\n",
      "  (0): HybridSequential(\n",
      "    (0): Conv2D(50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (2): Conv2D(50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (4): Conv2D(100, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "    (6): Conv2D(100, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
      "  )\n",
      "  (1): Flatten\n",
      "  (2): Dense(512, Activation(relu))\n",
      "  (3): Dense(10, linear)\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a80e4672de52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-845d0bf89d10>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, test_data, epochs)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m#  Keep a moving average of the losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m##########################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mcurr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 moving_loss = (curr_loss if ((i == 0) and (e == 0)) \n\u001b[1;32m     76\u001b[0m                                else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/mxnet/ndarray/ndarray.pyc\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_fc = 512\n",
    "num_classes = 10 #num_outputs\n",
    "convs = [(50,3,2), (50,3,2), (100,3,2), (100,3,2)]\n",
    "\n",
    "ctx = mx.cpu()\n",
    "cnn = BaseCNNClassifier(ctx)\n",
    "cnn.build_model(convs, num_fc, num_classes)\n",
    "cnn.compile_model(optimizer='adam')\n",
    "cnn.fit(train_data, test_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yield_batch(X, y, batchsize=64, shuffle=False):\n",
    "    \n",
    "    def shuffle_data(X, y):\n",
    "        s = np.arange(len(X))\n",
    "        np.random.shuffle(s)\n",
    "        X = X[s]\n",
    "        y = y[s]\n",
    "        return X, y\n",
    "\n",
    "    assert len(X) == len(y)\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y)\n",
    "    # Only complete batches are submitted\n",
    "    for i in range(len(X)//batchsize):\n",
    "        yield X[i*batchsize:(i+1)*batchsize], y[i*batchsize:(i+1)*batchsize]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
