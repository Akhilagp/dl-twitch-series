{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Deep Learning on AWS - Sentiment analysis on movie reviews\n",
    "\n",
    "Lets build a model to predict the sentiment of the movie review (Positive or Negative)\n",
    "\n",
    "@sunilmallya\n",
    "\n",
    "@jrhunt\n",
    "\n",
    "Dataset and use case credit to David Ping\n",
    "\n",
    "### Twitch Video Link: https://www.twitch.tv/videos/169476156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Dataset Overview\n",
    "\n",
    "The training and testing dataset is the IMDB movie review database.  \n",
    "\n",
    "It has 50,000 movie reviews that are labelled with either a negative(0) or a positive(1) sentiment. \n",
    "\n",
    "We will split the dataset into 25,000 reviews for training and 25,000 reviews for testing.\n",
    "\n",
    "## Download Link\n",
    "\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "For th easiest Deep Learning environment I recommend using the AWS using Deep Learning AMI, please read [this post on AWS AI Blog](https://aws.amazon.com/blogs/ai/the-aws-deep-learning-ami-now-with-ubuntu/) for detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n",
      "/usr/local/lib/python2.7/dist-packages/Theano-0.8.2-py2.7.egg/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "#https://keras.io/preprocessing/text/\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Process Movie Review Data\n",
    "\n",
    "The dataset can be downloaded from http://ai.stanford.edu/~amaas/data/sentiment/. We will process the unzipped raw reviews into traing and testing datasets for training and validation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = 'aclImdb'\n",
    "\n",
    "files = [path + '/train/pos/' + f for f in os.listdir(path + '/train/pos/')] +  \\\n",
    "    [path + '/train/neg/' + f for f in os.listdir(path + '/train/neg/')] +\\\n",
    "    [path + '/test/pos/' + f for f in os.listdir(path + '/test/pos/')] +\\\n",
    "    [path + '/test/neg/' + f for f in os.listdir(path + '/test/neg/')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "input_text  = []\n",
    "\n",
    "for fname in files:\n",
    "    with open(fname) as f:\n",
    "        input_text += [remove_tags(\" \".join(f.readlines()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "\n",
    "tok = Tokenizer(num_words)\n",
    "tok.fit_on_texts(input_text[:25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Training & test data;  input data (X) and Labels (Y) \n",
    "\n",
    "# Labels \n",
    "input_label = ([1] * 12500 + [0] * 12500) * 2\n",
    "\n",
    "# Words will be replaced with index        \n",
    "X_train = tok.texts_to_sequences(input_text[:25000])\n",
    "X_test  = tok.texts_to_sequences(input_text[25000:])\n",
    "y_train = input_label[:25000]\n",
    "y_test  = input_label[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#MAX Review Length\n",
    "MAX_LENGTH = 500\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "#http://mxnet.io/api/python/io.html#mxnet.io.NDArrayIter\n",
    "batch_size = 250\n",
    "train_iter = mx.io.NDArrayIter(X_train, y_train, batch_size, shuffle=True)\n",
    "test_iter = mx.io.NDArrayIter(X_test, y_test, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Time to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.Variable('data')\n",
    "target = mx.sym.Variable('softmax_label')  # placeholder for label\n",
    "\n",
    "emb = mx.sym.Embedding(data=data, input_dim=num_words, output_dim=32, name='embed') \n",
    "\n",
    "# MLP only accepts 1D vector, hence flatten\n",
    "f_data = mx.sym.Flatten(data=emb, name='flatten')\n",
    "fc1  = mx.sym.FullyConnected(data=f_data, num_hidden=250)\n",
    "act1 = mx.sym.Activation(data=fc1, act_type=\"relu\")  \n",
    "fc2 = mx.sym.FullyConnected(data=act1, num_hidden=2) \n",
    "mlp = mx.sym.SoftmaxOutput(data=fc2, label=target, name='softmax')\n",
    "\n",
    "# Lets visualize the network\n",
    "#mx.viz.plot_network(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.793280\n",
      "INFO:root:Epoch[0] Time cost=2.362\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.880280\n",
      "INFO:root:Epoch[1] Train-accuracy=0.950360\n",
      "INFO:root:Epoch[1] Time cost=2.323\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.859280\n",
      "INFO:root:Epoch[2] Train-accuracy=0.984000\n",
      "INFO:root:Epoch[2] Time cost=2.319\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.857160\n",
      "INFO:root:Epoch[3] Train-accuracy=0.983880\n",
      "INFO:root:Epoch[3] Time cost=2.323\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.849560\n",
      "INFO:root:Epoch[4] Train-accuracy=0.984000\n",
      "INFO:root:Epoch[4] Time cost=2.322\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.845560\n",
      "INFO:root:Epoch[5] Train-accuracy=0.988240\n",
      "INFO:root:Epoch[5] Time cost=2.322\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.842640\n",
      "INFO:root:Epoch[6] Train-accuracy=0.994600\n",
      "INFO:root:Epoch[6] Time cost=2.322\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.854720\n",
      "INFO:root:Epoch[7] Train-accuracy=0.999360\n",
      "INFO:root:Epoch[7] Time cost=2.321\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.852320\n",
      "INFO:root:Epoch[8] Train-accuracy=0.999960\n",
      "INFO:root:Epoch[8] Time cost=2.321\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.853000\n",
      "INFO:root:Epoch[9] Train-accuracy=1.000000\n",
      "INFO:root:Epoch[9] Time cost=2.325\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.853160\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "num_epoch = 10\n",
    "ctx = [mx.gpu(i) for i in range(1)]\n",
    "\n",
    "mlp_model = mx.mod.Module(symbol=mlp, context=ctx) \n",
    "mlp_model.fit(train_iter,              \n",
    "    eval_data=test_iter,                          \n",
    "    optimizer=\"adam\",  # use adam optimizer to train\n",
    "    optimizer_params={'learning_rate':0.01},        \n",
    "    eval_metric='acc',  \n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    "    num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model Evaluation\n",
    "We already evaluated the model during training.  Let's also try evaluating the trained model separately from the traing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accuracy', 0.85316)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "mlp_model.score(test_iter, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Saving The Model\n",
    "\n",
    "Now we have the model fully trained, we can save the model for reuse later\n",
    "2 files will be generated\n",
    "json file captures the network configuration of the neural network\n",
    "params file captures the learned parameters for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saved checkpoint to \"twitch_imdb-0010.params\"\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "prefix = \"twitch_imdb\"\n",
    "mlp_model.save_checkpoint (prefix, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Making Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/mxnet/python/mxnet/module/base_module.py:64: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "prefix = \"twitch_imdb\"\n",
    "pred_model = mx.mod.Module.load(prefix, num_epoch, False)\n",
    "\n",
    "# We load the model for only forward pass, so for_training=False\n",
    "# Set the data shape for 1 single batch example of size (1,500) => (batch_size, MAX_LENGTH)\n",
    "pred_model.bind(for_training=False, data_shapes=[('data', (1, MAX_LENGTH))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remember we need the input to test in the same format as we trained\n",
    "def prepare_imdb_list(text, maxlen=500, vocabsize=10000):\n",
    "\n",
    "    # the index to the vocabular we built earlier\n",
    "    imdb_word_index = tok.word_index \n",
    "    sentence = []\n",
    "    sentence.append(str(text))\n",
    "    \n",
    "    #tokenize the input sentence\n",
    "    tokens = Tokenizer()\n",
    "    tokens.fit_on_texts(sentence)\n",
    "\n",
    "    # get a list of words from the encoding\n",
    "    words = []\n",
    "    for iter in range(len(tokens.word_index)):\n",
    "        words += [key for key,value in tokens.word_index.items() if value==iter+1]\n",
    "\n",
    "    imdb_seq = []\n",
    "    for w in words:\n",
    "        idx = imdb_word_index[w]\n",
    "        if idx < vocabsize:\n",
    "            imdb_seq.append(idx)\n",
    "\n",
    "    new_list = []\n",
    "    new_list.append(imdb_seq)\n",
    "    new_list = pad_sequences(new_list, maxlen=maxlen)\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "\n",
    "def predict_sentiment(model, text_nd):\n",
    "    sentence_Iter = mx.io.NDArrayIter(text_nd, batch_size=1)\n",
    "    pred = pred_model.predict(sentence_Iter)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def handle_submit(sender):\n",
    "    text_nd = prepare_imdb_list(inputtext.value)\n",
    "    pred = predict_sentiment(pred_model, text_nd)\n",
    "    outputlabel_0.value = 'Probability for negative sentiment (0):  %0.4f ' % pred.asnumpy()[0:1,0]\n",
    "    outputlabel_1.value = 'Probability for positive sentiment (1):   %0.4f ' % pred.asnumpy()[0:1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lets have some fun with testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/ipywidgets/widgets/widget.py:166: DeprecationWarning: Widget._keys_default is deprecated in traitlets 4.1: use @default decorator instead.\n",
      "  def _keys_default(self):\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display \n",
    "from IPython.html import widgets\n",
    "inputtext = widgets.Textarea()\n",
    "\n",
    "display(inputtext)\n",
    "\n",
    "inputbutton = widgets.Button(description='Predict Sentiment')\n",
    "\n",
    "display(inputbutton)\n",
    "\n",
    "outputlabel_0 = widgets.HTML()\n",
    "outputlabel_1 = widgets.HTML()\n",
    "display(outputlabel_0)\n",
    "display(outputlabel_1)\n",
    "\n",
    "inputbutton.on_click(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More adventurous readers scroll below :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets try building an MLP model to do the same with MXNet's imperative interface Gluon\n",
    "\n",
    "Make sure you install it by running \n",
    "\n",
    "pip install mxnet --pre\n",
    "\n",
    "Gluon Tutorial: https://github.com/zackchase/mxnet-the-straight-dope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MXNet Gluon Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "import numpy as np\n",
    "\n",
    "ctx = mx.cpu()\n",
    "\n",
    "num_outputs = 2\n",
    "num_hidden = 256\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Embedding(vocabsize, 32, weight_initializer=mx.init.Uniform(0.1)))\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dropout(0.5))\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_outputs))\n",
    "    \n",
    "    \n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': .01})\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iterator, net, shape_n=500):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    data_iterator.reset()\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        data = batch.data[0].as_in_context(ctx).reshape((-1,shape_n))\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        acc.update(preds=predictions, labels=label)\n",
    "    return acc.get()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "moving_loss = 0.\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_data.reset()\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        data = batch.data[0].as_in_context(ctx).reshape((-1,500))\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            cross_entropy = loss(output, label)\n",
    "            cross_entropy.backward()\n",
    "        trainer.step(data.shape[0], ignore_stale_grad=True)\n",
    "        \n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        if i == 0:\n",
    "            moving_loss = nd.mean(cross_entropy).asscalar()\n",
    "        else:\n",
    "            moving_loss = .99 * moving_loss + .01 * nd.mean(cross_entropy).asscalar()\n",
    "            \n",
    "    test_accuracy = evaluate_accuracy(test_iter, net)\n",
    "    train_accuracy = evaluate_accuracy(train_iter, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" % (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.812929830771, 0.404830086653, 0.194560304798, 0.0949568697476, 0.0540652401239, 0.0192620222058, 0.0256203386385, 0.0162229706022, 0.0194205419608, 0.0193563111006]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0af00f3ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and see the curve\n",
    "\n",
    "content = '''Epoch 0. Loss: 0.812929830771, Train_acc 0.78576, Test_acc 0.7498\n",
    "Epoch 1. Loss: 0.404830086653, Train_acc 0.95528, Test_acc 0.86884\n",
    "Epoch 2. Loss: 0.194560304798, Train_acc 0.9746, Test_acc 0.8424\n",
    "Epoch 3. Loss: 0.0949568697476, Train_acc 0.98632, Test_acc 0.85032\n",
    "Epoch 4. Loss: 0.0540652401239, Train_acc 0.99656, Test_acc 0.84576\n",
    "Epoch 5. Loss: 0.0192620222058, Train_acc 0.99904, Test_acc 0.86436\n",
    "Epoch 6. Loss: 0.0256203386385, Train_acc 0.99788, Test_acc 0.85636\n",
    "Epoch 7. Loss: 0.0162229706022, Train_acc 0.99724, Test_acc 0.85216\n",
    "Epoch 8. Loss: 0.0194205419608, Train_acc 0.9978, Test_acc 0.84712\n",
    "Epoch 9. Loss: 0.0193563111006, Train_acc 0.99904, Test_acc 0.85124'''\n",
    "\n",
    "loss_points = [float(c.split(\" \")[3].rstrip(',')) for c in content.split('\\n')]\n",
    "print loss_points\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {
    "136fe89b2b614792afc82fbf8500b87c": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "521c04e239234a1e8bd290849f5e66ac": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "61584956af2c4aa4bc7e1a15c4067037": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    },
    "fe0a1c56419945b9adbb29eecf3d46b1": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
